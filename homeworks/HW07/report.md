# HW07 – Report

> Файл: `homeworks/HW07/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

Вы выбрали 3 датасета из 4 (перечислите):

### 1.1 Dataset A

- Файл: `S07-hw-dataset-01.csv`
- Размер: (12 000 строк, 9 столбцов)
- Признаки: все числовые (float64)
- Пропуски: нет
- "Подлости" датасета: признаки в сильно разных шкалах, наличие шумовых переменных, компактные кластеры

### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`
- Размер: (8 000 строк, 4 столбца)
- Признаки: все числовые (float64)
- Пропуски: нет
- "Подлости" датасета: нелинейная структура кластеров, явный шумовой признак (z_noise), выбросы

### 1.3 Dataset C

- Файл: `S07-hw-dataset-04.csv`
- Размер:  (10 000 строк, 33 столбца после препроцессинга)
- Признаки:  2 категориальных (cat_a, cat_b), остальные — числовые
- Пропуски:  есть (~1.7–2.2% в числовых признаках)
- "Подлости" датасета: высокая размерность после One-Hot Encoding, пропуски, смешанные типы признаков

### 1.3 Dataset D

- Файл: `S07-hw-dataset-03.csv`
- Размер: (15 000 строк, 5 столбца)
- Признаки: все числовые (float64)
- Пропуски: нет
- "Подлости" датасета: кластеры разной плотности + фоновый шум. Часто провоцирует ошибки выбора eps для DBSCAN.

## 2. Protocol

Опишите ваш "честный" unsupervised-протокол.

- Препроцессинг: 
  - Числовые признаки: SimpleImputer(strategy='median'), потом StandardScaler()
  - Категориальные признаки: SimpleImputer(strategy='constant', fill_value='missing'), OneHotEncoder(handle_unknown='ignore')
  - Использован ColumnTransformer + Pipeline; PCA не применялся при обучении моделей (только для визуализации)
- Поиск гиперпараметров:
  - KMeans: k: [5, 20], n_init=10, random_state=42
  - DBSCAN: eps: [0.15, 3.5] с шагом, зависящим от датасета; min_samples: [3, 5, 10]
  - Agglomerative: k: [4, 20], linkage: ['ward', 'complete', 'average']
  - Выбор лучшего — по silhouette_score (для DBSCAN — только по non-noise точкам)
- Метрики: 
  - Для DBSCAN метрики считались только по non-noise объектам (labels != -1)
  - Использованы: silhouette_score, davies_bouldin_score, calinski_harabasz_score
- Визуализация: PCA(2D) с random_state=42 для всех датасетов

## 3. Models

Перечислите, какие модели сравнивали **на каждом датасете**, и какие параметры подбирали.

Минимум (для каждого датасета):

- KMeans (k подбирался в диапазоне)
- DBSCAN (eps, min_samples) — для датасетов 1 и 4
- AgglomerativeClustering (k, linkage) — для датасетов 1-4

## 4. Results

Для каждого датасета – краткая сводка результатов.

### 4.1 Dataset A

- Лучший метод и параметры: DBSCAN (eps=0.6, min_samples=10)
- Метрики:
  - silhouette_score = 0.385
  - davies_bouldin_score = 1.24
  - calinski_harabasz_score = 8561.5
  - Доля шума: 1.9%
- Комментарий: DBSCAN выявил плотные группы без избыточного шума. В отличие от KMeans, не навязывает сферическую форму, что лучше соответствует структуре данных.

### 4.2 Dataset B

- Лучший метод и параметры: KMeans (k=16)
- Метрики:
  - silhouette_score = 0.284
  - davies_bouldin_score = 0.956
  - calinski_harabasz_score = 2329.4
- Комментарий: Несмотря на нелинейность и шум, KMeans обеспечил максимальное покрытие данных без маркировки как выбросов. DBSCAN помечал 13.6% точек как шум, и показал худший silhoulette

### 4.3 Dataset C

- Лучший метод и параметры: DBSCAN (eps=2.5, min_samples=6)
- Метрики:
  - silhouette_score = 0.507
  - davies_bouldin_score = 0.824
  - calinski_harabasz_score = 3916.5
  - Доля шума: 48.8%
- Комментарий: Высокая размерность после OHE требует увеличенного eps. DBSCAN позволил найти естественные плотностные группы без фиксированного числа кластеров, в отличие от KMeans/Agglomerative.

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- Наибольшее влияние оказали: масштабирование (обязательно для KMeans/DBSCAN), наличие шумовых признаков, высокая размерность и пропуски (в датасете 4);
- KMeans "ломается" при нелинейных формах (например, датасет 2), разной плотности (датасет 3) и высокой размерности (датасет 4). Он предполагает компактные, сферические кластеры одинаковой плотности;
- DBSCAN выигрывает, когда кластеры имеют произвольную форму и плотность (датасеты 1 и 4), а также при наличии шума.

### 5.2 Устойчивость (обязательно для одного датасета)

- Проверка устойчивости проведена на датасете 1: 5 запусков KMeans (n_init=10) с разными random_state;
- Результаты: средний попарный ARI = 0.92, NMI = 0.90 => высокая устойчивость;
- Вывод: решение устойчиво, так как KMeans с n_init=10 почти всегда находит одну и ту же структуру, несмотря на случайную инициализацию.

### 5.3 Интерпретация кластеров

- Интерпретация проводилась через средние значения признаков в каждом кластере (на основе исходных данных до PCA);
- В датасете 1 кластеры четко разделялись по значениям f01, f02 — что подтверждалось визуализацией;
- Например, в датасете 4 кластеры различались по комбинациям категориальных значений (cat_a, cat_b) и уровням числовых признаков (например, n01, n05).

## 6. Conclusion

Тезисы:
- Нет универсального метода. Выбор алгоритма должен основываться на структуре данных, а не только на метриках;
- KMeans надежен при компактных кластерах, но легко «ломается» на нелинейных или разреженных данных;
- Препроцессинг — ключевой этап, так как он корректная обработка пропусков и категориальных признаков критична в unsupervised-задачах;
- Silhouette_score не всегда достаточен — нужно учитывать долю шума, визуализацию и смысловую интерпретацию;
- DBSCAN мощен при сложной геометрии, но чувствителен к выбору eps и может маркировать много точек как шум;
- Устойчивость решений важна. Даже при хорошем silhouette, решение может быть нестабильным без достаточного n_init или правильного метода;
- PCA-визуализация помогает, но не заменяет количественную оценку.
