# HW06 – Report

> Файл: `homeworks/HW06/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Dataset

- Какой датасет выбран: `S06-hw-dataset-04.csv`
- Размер: (25000 строк, 62 столбцов)
- Целевая переменная: `target` (классы и их доли)
    - 0: 0.9508
    - 1: 0.0492
- Признаки: что за типы (числовые / категориальные-подобные, если есть)
    - Признаки числовые (float64).

## 2. Protocol

- Разбиение: train/test (доли, `random_state`)
  
    Данные разбиты на обучающую и тестовую выборки (test_size=0.25), с фиксированным random_state=42 и стратификацией по целевой переменной (stratify=y).
- Подбор: CV на train (сколько фолдов, что оптимизировали)
    - Гиперпараметры всех моделей подбирались с помощью StratifiedKFold(n_splits=5, shuffle=True, random_state=42);
    - В качестве целевой метрики для оптимизации использовался ROC-AUC, так как она устойчива к дисбалансу классов и отражает способность модели ранжировать объекты по вероятности принадлежности к положительному классу.
- Метрики: accuracy, F1, ROC-AUC (и почему эти метрики уместны именно здесь)
    - F1-score особенно важен для редкого класса (класс 1 составляет всего 0.0492), который представляет практический интерес;
    - ROC-AUC выбрана как основная метрика сравнения моделей: она корректно оценивает качество даже при сильном дисбалансе;
    - Accuracy даёт общее представление о доле правильных предсказаний, но может быть обманчиво высокой из-за доминирования класса 0 (95%).

## 3. Models

Опишите, какие модели сравнивали и какие гиперпараметры подбирали.

Минимум:

- DummyClassifier (baseline) - стратегия most_frequent (всегда предсказывает класс 0)
- LogisticRegression (baseline из S05) - с масштабированием StandartScaler:
    - `C`: [0.1, 1.0, 10.0]
    - `penalty`: "l2"
    - `solver`: "lbfgs"
- DecisionTreeClassifier (контроль сложности: `max_depth` + `min_samples_leaf` или `ccp_alpha`):
    - `max_depth`: [None, 3, 5, 8]
    - `min_samples_leaf`: [1, 5, 10, 20]
    - `ccp_alpha`: [0.0, 0.001, 0.005, 0.01]
- RandomForestClassifier:
    - `max_depth`: [None, 6, 10]
    - `min_samples_leaf`: [1, 5, 10]
    - `max_features`: ["sqrt", 0.5]
- Один boosting (HistGradientBoosting):
    - `learning_rate`: [0.03, 0.05, 0.1]
    - `max_depth`: [2, 3, None]
    - `max_leaf_nodes`: [15, 31, 63]

Опционально:

- StackingClassifier (с CV-логикой) - ансамбль из моделей:
    - `LogisticRegression`
    - `RandomForest`
    - `HistGradientBoosting`

## 4. Results

- Таблица/список финальных метрик на test по всем моделям

            accuracy 	    f1 	        roc_auc 	model
        5 	0.98160 	0.776699 	0.906041 	Stacking
        4 	0.97984 	0.742857 	0.904646 	HistGradientBoosting
        3 	0.97024 	0.567442 	0.903552 	RandomForest
        1 	0.96256 	0.409091 	0.840041 	LogReg(scaled)
        2 	0.96848 	0.588727 	0.827972 	DecisionTree
        0 	0.95088 	0.000000 	0.500000 	Dummy(most_frequent)

- Победитель (по ROC-AUC или по согласованному критерию) и краткое объяснение
    - Победитель - Stacking
    - ROC-AUC: 0.906041
    - accuracy: 0.98160
    - f1: 0.776699
    - Stacking позволил объединить линейный алгоритм LogReg, деревья RandomForest и градиентный бустинг HistGradientBoosting, что дало прирост в качестве

## 5. Analysis

- Устойчивость: что будет, если поменять `random_state` (хотя бы 5 прогонов для 1-2 моделей) – кратко
    
    Таблица результатов **DecisionTree** с разными значениями `random_state`:

 	            accuracy 	    f1 	        roc_auc
            2 	0.96848 	0.588727 	0.827972
            9 	0.96848 	0.588727 	0.824732
            7 	0.96848 	0.588727 	0.819604
            6 	0.96656 	0.560000 	0.799189
            8 	0.96656 	0.560000 	0.799112

    Исходя из таблицы, можно сказать, что изменения `random_state` существенно не влияют на качество, что говорит об отсутствии переобучения, а также о надежности. Несмотря на то, что ROC-AUC варьируется от 0.799112 до 0.827972, модель остается стабильной.

- Ошибки: confusion matrix для лучшей модели + комментарий
    - TP (True Positive): 200 - модель успешно выявляет большинство из реально существующих редких событий;
    - TN (True Negative): 5935 - модель почти безошибочно определяет основной класс (0);
    - FP (False Positive): 8 - крайне редко ошибается, предсказывая "1" вместо "0" — это важно, если ложные срабатывания дорогостоящие;
    - FN (False Negative): 107 - модель успешно выявляет большинство из реально существующих редких событий.

    Такой баланс типичен для задач с дисбалансом, так как она предпочтет не выдать ложное срабатывание даже ценой пропуска реальных событий.
- Интерпретация: permutation importance (top-15) + выводы
    Permutation importance (важность признаков по перестановке) - это метод оценки вклада каждого признака в качество модели.
    - Топ-15 признаков: f54, f25, f58, f33, f04, f53, f38, f47, f41, f08, f50, f36, f07, f13, f43;
    - Признак f54 оказывает наибольшее влияние, его перемешивание снижает качество на 1.75%;
    - Признаки f25 и f58, находящиеся после f54, также сильно влияют на предсказания, возможно они логически связаны со смыслом целевой переменной;
    - Присутствуют группы признаков, которые, возможно, описывают схожие свойства, так как они примерно равны по значению: [f33, f04, f53], [f38, f47, f41, f08], [f50, f36, f07, f13, f43].

## 6. Conclusion

3-6 коротких тезисов: что вы поняли про деревья/ансамбли и про честный ML-протокол.
- Ансамбли (особенно стэкинг) демонстрируют явное преимущество над одиночными моделями, особенно в условиях дисбаланса классов — их способность комбинировать различные гипотезы критически важна;
- Деревья требуют тщательной регуляризации. Без ограничений (max_depth, min_samples_leaf и т.п.) они склонны к переобучению, особенно на малом классе;
- Accuracy вводит в заблуждение при сильном дисбалансе. DummyClassifier достигает 95% accuracy, но бесполезен. ROC-AUC и F1-score — обязательные метрики в таких задачах;
- Честный ML-протокол (стратифицированное разбиение, CV только на train, финальная оценка — один раз на test) — единственный способ получить достоверную оценку обобщающей способности;
- Даже сложные ансамбли можно интерпретировать. Permutation importance показала, что модель опирается на осмысленные признаки, а не на случайные артефакты — это важно для доверия и внедрения.